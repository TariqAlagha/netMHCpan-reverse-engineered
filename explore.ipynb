{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4999b028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>binding_affinity</th>\n",
       "      <th>mhc_allele</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAYAAM</td>\n",
       "      <td>0.177415</td>\n",
       "      <td>H-2-Db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAYAAM</td>\n",
       "      <td>0.463100</td>\n",
       "      <td>H-2-Kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAFEAAL</td>\n",
       "      <td>0.362118</td>\n",
       "      <td>BoLA-3:00101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAFEAAL</td>\n",
       "      <td>0.468035</td>\n",
       "      <td>BoLA-3:00201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAFEAAL</td>\n",
       "      <td>0.522653</td>\n",
       "      <td>HLA-B48:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      peptide  binding_affinity    mhc_allele\n",
       "0  AAAAAAYAAM          0.177415        H-2-Db\n",
       "1  AAAAAAYAAM          0.463100        H-2-Kb\n",
       "2   AAAAFEAAL          0.362118  BoLA-3:00101\n",
       "3   AAAAFEAAL          0.468035  BoLA-3:00201\n",
       "4   AAAAFEAAL          0.522653    HLA-B48:01"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = ['data/netMHCpan_training_data/BA/c000_ba', 'data/netMHCpan_training_data/BA/c001_ba', \n",
    "        'data/netMHCpan_training_data/BA/c002_ba', 'data/netMHCpan_training_data/BA/c003_ba', \n",
    "        'data/netMHCpan_training_data/BA/c004_ba']\n",
    "fullFrame = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep=r'\\s+', header=None, names=['peptide', 'binding_affinity', 'mhc_allele'])\n",
    "    fullFrame = pd.concat([fullFrame, df], axis=0, ignore_index=True)\n",
    "\n",
    "# ensure numeric target\n",
    "fullFrame['binding_affinity'] = pd.to_numeric(fullFrame['binding_affinity'], errors='coerce')\n",
    "fullFrame = fullFrame.dropna(subset=['binding_affinity']).reset_index(drop=True)\n",
    "\n",
    "fullFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b0cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BabyNetMHCpan(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Peptide: one-hot encode → small CNN\n",
    "        self.peptide_encoder = nn.Conv1d(20, 64, kernel_size=3)\n",
    "        \n",
    "        # MHC: pseudo-sequence → embedding\n",
    "        self.mhc_encoder = nn.Linear(34 * 20, 64)  # Just flatten one-hot\n",
    "        \n",
    "        # Combine and predict\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()  # Output in [0,1] for BA\n",
    "        )\n",
    "    \n",
    "    def forward(self, peptide, mhc_pseudo):\n",
    "        # The magic happens here\n",
    "        p = F.relu(self.peptide_encoder(peptide))\n",
    "        p = F.adaptive_max_pool1d(p, 1).squeeze(-1)\n",
    "\n",
    "        if mhc_pseudo.dim() == 3:\n",
    "            mhc_pseudo = mhc_pseudo.reshape(mhc_pseudo.size(0), -1)\n",
    "        m = F.relu(self.mhc_encoder(mhc_pseudo))\n",
    "\n",
    "        z = torch.cat([p, m], dim=1)\n",
    "        return self.predictor(z)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9b7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHC pseudo coverage: 100.0% of BA rows\n"
     ]
    }
   ],
   "source": [
    "# Parse MHC pseudo-sequences and compute coverage vs BA rows\n",
    "from pathlib import Path\n",
    "\n",
    "pseudo_path = Path('data/netMHCpan_training_data/MHC_pseudo.dat')\n",
    "allele_to_pseudo_raw = {}\n",
    "with pseudo_path.open() as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#'):\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        allele, seq = parts[0], parts[1]\n",
    "        allele_to_pseudo_raw[allele] = seq\n",
    "\n",
    "# Keep only canonical 34-aa pseudo sequences to match model expectation (34 * 20)\n",
    "allele_to_pseudo = {a: s for a, s in allele_to_pseudo_raw.items() if len(s) == 34}\n",
    "\n",
    "coverage = (fullFrame['mhc_allele'].isin(allele_to_pseudo)).mean()\n",
    "print(f\"MHC pseudo coverage: {coverage*100:.1f}% of BA rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4165f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canonicalize allele names to improve pseudo coverage and matching\n",
    "import re\n",
    "\n",
    "def canonicalize_allele(a: str) -> str:\n",
    "    if not isinstance(a, str):\n",
    "        return \"\"\n",
    "    return re.sub(r\"[^A-Za-z0-9]\", \"\", a).lower()\n",
    "\n",
    "# Build canonical map for 34-aa pseudos\n",
    "canon_to_pseudo_all = {canonicalize_allele(a): s for a, s in allele_to_pseudo_raw.items()}\n",
    "canon_to_pseudo_34 = {k: v for k, v in canon_to_pseudo_all.items() if len(v) == 34}\n",
    "\n",
    "# Compare exact vs canonical coverage\n",
    "exact_cov = (fullFrame['mhc_allele'].isin(allele_to_pseudo)).mean()\n",
    "canon_cov = fullFrame['mhc_allele'].map(lambda a: canonicalize_allele(a) in canon_to_pseudo_34).mean()\n",
    "print(f\"Exact-name coverage: {exact_cov*100:.1f}% | Canonical coverage: {canon_cov*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f957a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding utilities\n",
    "import string\n",
    "\n",
    "AMINO_ACIDS = list(\"ACDEFGHIKLMNPQRSTVWY\")  # 20 standard AAs in fixed order\n",
    "AA_TO_INDEX = {aa: i for i, aa in enumerate(AMINO_ACIDS)}\n",
    "\n",
    "\n",
    "def one_hot_sequence(seq: str, vocab=AA_TO_INDEX, num_channels=20):\n",
    "    # shape: (C, L) for Conv1d\n",
    "    import torch\n",
    "    L = len(seq)\n",
    "    x = torch.zeros(num_channels, L, dtype=torch.float32)\n",
    "    for pos, aa in enumerate(seq):\n",
    "        idx = vocab.get(aa)\n",
    "        if idx is not None:\n",
    "            x[idx, pos] = 1.0\n",
    "    return x\n",
    "\n",
    "\n",
    "def one_hot_pseudo(seq: str, num_channels=20):\n",
    "    # shape: (34, 20) then we will flatten to (34*20) or keep as (34,20)\n",
    "    import torch\n",
    "    L = len(seq)\n",
    "    x = torch.zeros(L, num_channels, dtype=torch.float32)\n",
    "    for pos, aa in enumerate(seq):\n",
    "        idx = AA_TO_INDEX.get(aa)\n",
    "        if idx is not None:\n",
    "            x[pos, idx] = 1.0\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e67d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208093"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch Dataset for BA data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BADataset(Dataset):\n",
    "    def __init__(self, df, allele_to_pseudo):\n",
    "        # Filter rows to those we have pseudo sequences for\n",
    "        self.df = df[df['mhc_allele'].isin(allele_to_pseudo)].reset_index(drop=True)\n",
    "        self.allele_to_pseudo = allele_to_pseudo\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        peptide = row['peptide']\n",
    "        allele = row['mhc_allele']\n",
    "        y = float(row['binding_affinity'])\n",
    "        pep_oh = one_hot_sequence(peptide)  # (20, L)\n",
    "        pseudo_oh = one_hot_pseudo(self.allele_to_pseudo[allele])  # (34, 20)\n",
    "        return pep_oh, pseudo_oh, y\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # Pad peptides to the max length in the batch on the right with zeros\n",
    "    import torch\n",
    "    pep_list, pseudo_list, y_list = zip(*batch)\n",
    "    max_len = max(t.shape[1] for t in pep_list)\n",
    "    padded_peps = []\n",
    "    for t in pep_list:\n",
    "        if t.shape[1] < max_len:\n",
    "            pad = torch.zeros(t.shape[0], max_len - t.shape[1])\n",
    "            t = torch.cat([t, pad], dim=1)\n",
    "        padded_peps.append(t)\n",
    "    pep_tensor = torch.stack(padded_peps, dim=0)  # (B, 20, Lmax)\n",
    "\n",
    "    pseudo_tensor = torch.stack(pseudo_list, dim=0)  # (B, 34, 20)\n",
    "    y_tensor = torch.tensor(y_list, dtype=torch.float32).unsqueeze(-1)  # (B,1)\n",
    "    return pep_tensor, pseudo_tensor, y_tensor\n",
    "\n",
    "\n",
    "dataset = BADataset(fullFrame, allele_to_pseudo)\n",
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c87674e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187283, 20810)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/val split and DataLoaders\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, val_idx = train_test_split(range(len(dataset)), test_size=0.1, random_state=42)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_batch, num_workers=0)\n",
    "\n",
    "len(train_ds), len(val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ab7f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | val MSE: 0.0656\n",
      "Epoch 2 | val MSE: 0.0568\n",
      "Epoch 3 | val MSE: 0.0531\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and simple training loop\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BabyNetMHCpan().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    loss_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for pep, pseudo, y in loader:\n",
    "            pep = pep.to(device)\n",
    "            pseudo = pseudo.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(pep, pseudo)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "            n += y.size(0)\n",
    "    return loss_sum / max(n, 1)\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    for pep, pseudo, y in train_loader:\n",
    "        pep = pep.to(device)\n",
    "        pseudo = pseudo.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(pep, pseudo)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    val_loss = evaluate(val_loader)\n",
    "    print(f\"Epoch {epoch} | val MSE: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e435b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 20, 12]) torch.Size([256, 34, 20]) torch.Size([256, 1])\n",
      "torch.Size([256, 1]) [0.10367729 0.33692557 0.63325983 0.07783097 0.3745204 ]\n"
     ]
    }
   ],
   "source": [
    "# Sanity-check one forward pass\n",
    "pep, pseudo, y = next(iter(train_loader))\n",
    "print(pep.shape, pseudo.shape, y.shape)\n",
    "with torch.no_grad():\n",
    "    out = model(pep.to(device), pseudo.to(device))\n",
    "print(out.shape, out[:5].squeeze().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d06675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation metrics (Pearson/Spearman) on the val set (SciPy optional)\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from scipy.stats import pearsonr, spearmanr  # type: ignore\n",
    "    use_scipy = True\n",
    "except Exception:\n",
    "    use_scipy = False\n",
    "\n",
    "model.eval()\n",
    "all_y, all_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for pep, pseudo, y in val_loader:\n",
    "        y = y.numpy().ravel()\n",
    "        pred = model(pep.to(device), pseudo.to(device)).cpu().numpy().ravel()\n",
    "        all_y.append(y)\n",
    "        all_pred.append(pred)\n",
    "all_y = np.concatenate(all_y)\n",
    "all_pred = np.concatenate(all_pred)\n",
    "\n",
    "if use_scipy:\n",
    "    p = pearsonr(all_y, all_pred)[0]\n",
    "    s = spearmanr(all_y, all_pred)[0]\n",
    "else:\n",
    "    # Pearson without SciPy\n",
    "    y_mean = all_y.mean(); p_mean = all_pred.mean()\n",
    "    num = ((all_y - y_mean) * (all_pred - p_mean)).sum()\n",
    "    den = np.sqrt(((all_y - y_mean) ** 2).sum()) * np.sqrt(((all_pred - p_mean) ** 2).sum())\n",
    "    p = num / (den + 1e-12)\n",
    "    # Spearman via rank correlation\n",
    "    y_rank = all_y.argsort().argsort().astype(float)\n",
    "    p_rank = all_pred.argsort().argsort().astype(float)\n",
    "    yrm = y_rank.mean(); prm = p_rank.mean()\n",
    "    s_num = ((y_rank - yrm) * (p_rank - prm)).sum()\n",
    "    s_den = np.sqrt(((y_rank - yrm) ** 2).sum()) * np.sqrt(((p_rank - prm) ** 2).sum())\n",
    "    s = s_num / (s_den + 1e-12)\n",
    "\n",
    "print(f\"Pearson: {p:.3f} | Spearman: {s:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model helper and quick inference function\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "ckpt_path = Path('tmp/baby_netmhcpan.pt')\n",
    "ckpt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_model(model, path=ckpt_path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f'Saved to {path}')\n",
    "\n",
    "\n",
    "def predict_peptide_allele(peptide: str, allele: str):\n",
    "    akey = canonicalize_allele(allele)\n",
    "    if akey not in canon_to_pseudo_34:\n",
    "        raise ValueError(f'No pseudo for allele {allele}')\n",
    "    pep = one_hot_sequence(peptide).unsqueeze(0)  # (1, 20, L)\n",
    "    pseudo = one_hot_pseudo(canon_to_pseudo_34[akey]).unsqueeze(0)  # (1, 34, 20)\n",
    "    with torch.no_grad():\n",
    "        pred = model(pep.to(device), pseudo.to(device)).item()\n",
    "    return pred\n",
    "\n",
    "# Example usage (after training):\n",
    "# save_model(model)\n",
    "# predict_peptide_allele('SIINFEKL', 'H-2-Kb')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netMHCpan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
